{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of timedate when it was published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Page 1 ===\n",
      "start: 0  total: 490708\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "base = 'https://dataverse.harvard.edu'\n",
    "rows = 1000\n",
    "start = 0\n",
    "page = 1\n",
    "condition = True # emulate do-while\n",
    "prueba = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=2)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "prueba.mount('http://', adapter)\n",
    "prueba.mount('https://', adapter)\n",
    "scraping_types=pd.DataFrame(columns=['Type'])\n",
    "scraping_names=pd.DataFrame(columns=['Name'])\n",
    "scraping_publication=pd.DataFrame(columns=['PublicationDate'])\n",
    "\n",
    "\n",
    "\n",
    "while (condition):\n",
    "    url = base + '/api/search?q=*&type=file&show_facets=true&per_page=1000' + \"&start=\" + str(start)\n",
    "    data = json.loads(prueba.get(url).text)\n",
    "    total = data['data']['total_count']\n",
    "    print(\"=== Page\", page, \"===\")\n",
    "    print(\"start:\", start, \" total:\", total)\n",
    "    for i in data['data']['items']:\n",
    "        scraping_types=scraping_types.append(pd.DataFrame([i['type']], columns=['Type']))\n",
    "        scraping_names=scraping_names.append(pd.DataFrame([i['name']], columns=['Name']))\n",
    "        scraping_publication=scraping_publication.append(pd.DataFrame([i['published_at']], columns=['PublicationDate']))\n",
    "\n",
    "\n",
    "    start = start + rows\n",
    "    page += 1\n",
    "    condition = start < total/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "base = 'https://dataverse.harvard.edu'\n",
    "rows = 10\n",
    "start = 0\n",
    "page = 1\n",
    "condition = True # emulate do-while\n",
    "prueba = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=2)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "prueba.mount('http://', adapter)\n",
    "prueba.mount('https://', adapter)\n",
    "filetypes_count=pd.DataFrame(columns=['count'])\n",
    "filetypes_name=pd.DataFrame(columns=['name'])\n",
    "\n",
    "url = base + '/api/search?q=*&type=file&show_facets=true&per_page=1' + \"&start=\" + str(start)\n",
    "data = json.loads(prueba.get(url).text)\n",
    "total = data['data']['total_count']\n",
    "print(\" total:\", total)\n",
    "\n",
    "    \n",
    "for i in data['data']['facets']:\n",
    "    for d in i['fileTypeGroupFacet']['labels']:\n",
    "        for j in d:\n",
    "            filetypes_count=filetypes_count.append(pd.DataFrame([d[j]], columns=['count']))\n",
    "            filetypes_name=filetypes_name.append(pd.DataFrame([j], columns=['name']))\n",
    "\n",
    "final=pd.concat([filetypes_name,filetypes_count],axis=1).reset_index()\n",
    "\n",
    "\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.iloc[:, 1:].to_csv('fileformats.csv',sep=\",\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index          name   count\n",
      "index                             \n",
      "0          0          Data  114574\n",
      "1          0       Unknown   71564\n",
      "2          0      Document   59287\n",
      "3          0  Tabular Data   47734\n",
      "4          0          Text   45593\n",
      "5          0         Image   40544\n",
      "6          0   Application   23722\n",
      "7          0           ZIP    5894\n",
      "8          0          FITS    4995\n",
      "9          0         Audio    3618\n",
      "10         0         Video     940\n",
      "11         0         Shape     871\n",
      "12         0  Network Data      55\n",
      "13         0      Chemical       9\n",
      "14         0        Binary       7\n",
      "15         0         Model       2\n"
     ]
    }
   ],
   "source": [
    "final.index.name = 'index'\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PublicationDate\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "0   2011-12-13T00:00:00Z\n",
      "..                   ...\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "0   2015-04-09T03:06:40Z\n",
      "\n",
      "[3000 rows x 1 columns]\n",
      "                              Name\n",
      "0                        Shapefile\n",
      "0                        Shapefile\n",
      "0                        Shapefile\n",
      "0                            Shape\n",
      "0                             TIFF\n",
      "0                             TIFF\n",
      "0                            Shape\n",
      "0                         JPEG2000\n",
      "0                            Shape\n",
      "0                            Shape\n",
      "0                             TIFF\n",
      "0                            Shape\n",
      "0                        Shapefile\n",
      "0                            Shape\n",
      "0                             TIFF\n",
      "0                            Shape\n",
      "0                            Shape\n",
      "0                         JPEG2000\n",
      "0                             TIFF\n",
      "0                            Shape\n",
      "0                         JPEG2000\n",
      "0                            Shape\n",
      "0                            Shape\n",
      "0                             TIFF\n",
      "0                            Shape\n",
      "0                            Shape\n",
      "0                         JPEG2000\n",
      "0                            Shape\n",
      "0                            SHAPE\n",
      "0                             TIFF\n",
      "..                             ...\n",
      "0              Florida Work County\n",
      "0         Georgia Residence County\n",
      "0              Georgia Work County\n",
      "0          Hawaii Residence County\n",
      "0               Hawaii Work County\n",
      "0           Idaho Residence County\n",
      "0                Idaho Work County\n",
      "0        Illinois Residence County\n",
      "0             Illinois Work County\n",
      "0         Indiana Residence County\n",
      "0              Indiana Work County\n",
      "0            Iowa Residence County\n",
      "0                 Iowa Work County\n",
      "0          Kansas Residence County\n",
      "0               Kansas Work County\n",
      "0        Kentucky Residence County\n",
      "0             Kentucky Work County\n",
      "0       Louisiana Residence County\n",
      "0            Louisiana Work County\n",
      "0           Maine Residence County\n",
      "0                Maine Work County\n",
      "0        Maryland Residence County\n",
      "0             Maryland Work County\n",
      "0   Massachusetts Residence County\n",
      "0        Massachusetts Work County\n",
      "0        Michigan Residence County\n",
      "0             Michigan Work County\n",
      "0       Minnesota Residence County\n",
      "0            Minnesota Work County\n",
      "0     Mississippi Residence County\n",
      "\n",
      "[3000 rows x 1 columns]\n",
      "    Type\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "..   ...\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "0   file\n",
      "\n",
      "[3000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(scraping_publication)\n",
    "print(scraping_names)\n",
    "print(scraping_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([scraping_publication,scraping_names,scraping_types, scraping_publicationtime],axis=1).reset_index()\n",
    "final.to_csv('datasearch.csv',sep=\",\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PublicationTime\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "..             ...\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "0            00:00\n",
      "\n",
      "[88000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "scraping_publicationtime=pd.DataFrame(columns=['PublicationTime'])\n",
    "\n",
    "holi=pd.DataFrame(scraping_publication['PublicationDate'])\n",
    "holi['PublicationDate'] = pd.to_datetime(holi['PublicationDate'])\n",
    "for i in holi['PublicationDate']:\n",
    "    i= i-datetime.timedelta(minutes=i.minute % 10,\n",
    "                             seconds=i.second,\n",
    "                             microseconds=i.microsecond)\n",
    "    i += datetime.timedelta(minutes=5)\n",
    "    i -= datetime.timedelta(minutes=i.minute % 10,\n",
    "                         seconds=i.second,\n",
    "                         microseconds=i.microsecond)\n",
    "    i=i.strftime(\"%H:%M\")\n",
    "    scraping_publicationtime=scraping_publicationtime.append(pd.DataFrame([i], columns=['PublicationTime']))\n",
    "print(scraping_publicationtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PublicationTime  level_0  index  Type\n",
      "0              00:00        0      0  file\n",
      "1              00:00        1      0  file\n",
      "2              00:00        2      0  file\n",
      "3              00:00        3      0  file\n",
      "4              00:00        4      0  file\n",
      "5              00:00        5      0  file\n",
      "6              00:00        6      0  file\n",
      "7              00:00        7      0  file\n",
      "8              00:00        8      0  file\n",
      "9              00:00        9      0  file\n",
      "10             00:00       10      0  file\n",
      "11             00:00       11      0  file\n",
      "12             00:00       12      0  file\n",
      "13             00:00       13      0  file\n",
      "14             00:00       14      0  file\n",
      "15             00:00       15      0  file\n",
      "16             00:00       16      0  file\n",
      "17             00:00       17      0  file\n",
      "18             00:00       18      0  file\n",
      "19             00:00       19      0  file\n",
      "20             00:00       20      0  file\n",
      "21             00:00       21      0  file\n",
      "22             00:00       22      0  file\n",
      "23             00:00       23      0  file\n",
      "24             00:00       24      0  file\n",
      "25             00:00       25      0  file\n",
      "26             00:00       26      0  file\n",
      "27             00:00       27      0  file\n",
      "28             00:00       28      0  file\n",
      "29             00:00       29      0  file\n",
      "...              ...      ...    ...   ...\n",
      "4970           03:10     4970      0  file\n",
      "4971           03:10     4971      0  file\n",
      "4972           03:10     4972      0  file\n",
      "4973           03:10     4973      0  file\n",
      "4974           03:10     4974      0  file\n",
      "4975           03:10     4975      0  file\n",
      "4976           03:10     4976      0  file\n",
      "4977           03:10     4977      0  file\n",
      "4978           03:10     4978      0  file\n",
      "4979           03:10     4979      0  file\n",
      "4980           03:10     4980      0  file\n",
      "4981           03:10     4981      0  file\n",
      "4982           03:10     4982      0  file\n",
      "4983           03:10     4983      0  file\n",
      "4984           03:10     4984      0  file\n",
      "4985           03:10     4985      0  file\n",
      "4986           03:10     4986      0  file\n",
      "4987           03:10     4987      0  file\n",
      "4988           03:10     4988      0  file\n",
      "4989           03:10     4989      0  file\n",
      "4990           03:10     4990      0  file\n",
      "4991           03:10     4991      0  file\n",
      "4992           03:10     4992      0  file\n",
      "4993           03:10     4993      0  file\n",
      "4994           03:10     4994      0  file\n",
      "4995           03:10     4995      0  file\n",
      "4996           03:10     4996      0  file\n",
      "4997           03:10     4997      0  file\n",
      "4998           03:10     4998      0  file\n",
      "4999           03:10     4999      0  file\n",
      "\n",
      "[5000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "scraping_publicationtime=pd.DataFrame(scraping_publicationtime, columns=['PublicationTime'])\n",
    "scraping=pd.concat([scraping_publicationtime,scraping_types], axis=1)\n",
    "print(scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 index\n",
      "PublicationTime       \n",
      "00:00            34075\n",
      "03:00             4154\n",
      "03:10             6050\n",
      "03:20             6236\n",
      "03:30             7003\n",
      "03:40             7437\n",
      "03:50             9355\n",
      "04:00             7560\n",
      "04:10             6111\n",
      "18:30               19\n"
     ]
    }
   ],
   "source": [
    "scraping2=scraping_publicationtime.reset_index().groupby('PublicationTime').count()\n",
    "print(scraping2)\n",
    "scraping2.to_csv(\"data_circular.csv\", sep=\";\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x06DFA870>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas\n",
    "with open('datasearchFINAL.csv', 'r') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    print(spamreader)\n",
    "    index=pd.DataFrame(columns=[\"index\"])\n",
    "    PublicationTime=pd.DataFrame(columns=[\"PublicationTime\"])\n",
    "    for j in spamreader:\n",
    "            index=index.append(pd.DataFrame([int(j[1])], columns=[\"index\"]))\n",
    "            PublicationTime=PublicationTime.append(pd.DataFrame([j[0]], columns=[\"PublicationTime\"]))\n",
    "    holi=pd.concat([PublicationTime, index],axis=1)\n",
    "    holi3=holi.groupby('PublicationTime')['index'].sum()\n",
    "    holi3.to_csv(\"data_circularFINAL.csv\", sep=\",\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
